{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# objective is to get the cart to the flag.\r\n",
    "# for now, let's just move randomly:\r\n",
    "\r\n",
    "import gym\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "env = gym.make(\"MountainCar-v0\")\r\n",
    "\r\n",
    "LEARNING_RATE = 0.1\r\n",
    "\r\n",
    "DISCOUNT = 0.95\r\n",
    "EPISODES = 25000\r\n",
    "SHOW_EVERY = 3000\r\n",
    "\r\n",
    "DISCRETE_OS_SIZE = [20, 20]\r\n",
    "discrete_os_win_size = (env.observation_space.high - env.observation_space.low)/DISCRETE_OS_SIZE\r\n",
    "\r\n",
    "# Exploration settings\r\n",
    "epsilon = 1  # not a constant, qoing to be decayed\r\n",
    "START_EPSILON_DECAYING = 1\r\n",
    "END_EPSILON_DECAYING = EPISODES//2\r\n",
    "epsilon_decay_value = epsilon/(END_EPSILON_DECAYING - START_EPSILON_DECAYING)\r\n",
    "\r\n",
    "\r\n",
    "q_table = np.random.uniform(low=-2, high=0, size=(DISCRETE_OS_SIZE + [env.action_space.n]))\r\n",
    "\r\n",
    "\r\n",
    "def get_discrete_state(state):\r\n",
    "    discrete_state = (state - env.observation_space.low)/discrete_os_win_size\r\n",
    "    return tuple(discrete_state.astype(np.int))  # we use this tuple to look up the 3 Q values for the available actions in the q-table\r\n",
    "\r\n",
    "\r\n",
    "for episode in range(EPISODES):\r\n",
    "    discrete_state = get_discrete_state(env.reset())\r\n",
    "    done = False\r\n",
    "\r\n",
    "    if episode % SHOW_EVERY == 0:\r\n",
    "        render = True\r\n",
    "        print(episode)\r\n",
    "    else:\r\n",
    "        render = False\r\n",
    "\r\n",
    "    while not done:\r\n",
    "\r\n",
    "        if np.random.random() > epsilon:\r\n",
    "            # Get action from Q table\r\n",
    "            action = np.argmax(q_table[discrete_state])\r\n",
    "        else:\r\n",
    "            # Get random action\r\n",
    "            action = np.random.randint(0, env.action_space.n)\r\n",
    "\r\n",
    "\r\n",
    "        new_state, reward, done, _ = env.step(action)\r\n",
    "\r\n",
    "        new_discrete_state = get_discrete_state(new_state)\r\n",
    "\r\n",
    "        if episode % SHOW_EVERY == 0:\r\n",
    "            env.render()\r\n",
    "        #new_q = (1 - LEARNING_RATE) * current_q + LEARNING_RATE * (reward + DISCOUNT * max_future_q)\r\n",
    "\r\n",
    "        # If simulation did not end yet after last step - update Q table\r\n",
    "        if not done:\r\n",
    "\r\n",
    "            # Maximum possible Q value in next step (for new state)\r\n",
    "            max_future_q = np.max(q_table[new_discrete_state])\r\n",
    "\r\n",
    "            # Current Q value (for current state and performed action)\r\n",
    "            current_q = q_table[discrete_state + (action,)]\r\n",
    "\r\n",
    "            # And here's our equation for a new Q value for current state and action\r\n",
    "            new_q = (1 - LEARNING_RATE) * current_q + LEARNING_RATE * (reward + DISCOUNT * max_future_q)\r\n",
    "\r\n",
    "            # Update Q table with new Q value\r\n",
    "            q_table[discrete_state + (action,)] = new_q\r\n",
    "\r\n",
    "\r\n",
    "        # Simulation ended (for any reson) - if goal position is achived - update Q value with reward directly\r\n",
    "        elif new_state[0] >= env.goal_position:\r\n",
    "            #q_table[discrete_state + (action,)] = reward\r\n",
    "            q_table[discrete_state + (action,)] = 0\r\n",
    "\r\n",
    "        discrete_state = new_discrete_state\r\n",
    "\r\n",
    "    # Decaying is being done every episode if episode number is within decaying range\r\n",
    "    if END_EPSILON_DECAYING >= episode >= START_EPSILON_DECAYING:\r\n",
    "        epsilon -= epsilon_decay_value\r\n",
    "\r\n",
    "\r\n",
    "env.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp/ipykernel_24364/1486997342.py:30: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return tuple(discrete_state.astype(np.int))  # we use this tuple to look up the 3 Q values for the available actions in the q-table\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24364/1486997342.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mnew_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mnew_discrete_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_discrete_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepisode\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mSHOW_EVERY\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24364/1486997342.py\u001b[0m in \u001b[0;36mget_discrete_state\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_discrete_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mdiscrete_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdiscrete_os_win_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscrete_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# we use this tuple to look up the 3 Q values for the available actions in the q-table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('env-anaconda': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "bc01fbfd248a7e63fd42508171f6ad4276b070e66e0eb2da8e62d07ab8747ac5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}